{"cells":[{"cell_type":"markdown","source":["##Housekeeping script for all lines\nThis script contains common configurations needed to transform all lines. \n\n###Configuration variables/set up included in this script:\n1. Authentication detail to connect to Kafka topic on Confluent cluster\n2. The check point location, output root directory, and trigger interval for the data stream\n3. The output directory of DF_RUN (for RCA)\n4. The technical schema of Kafka messages\n5. Schema of the pivot-schema table\n6. Column name mapping and schema of mapped fields for running the business schema mapping logic\n7. Create local business-schema-mapping table and source-meta-data table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"246ba9d3-ae01-4c8a-86ab-3d39722dd344"}}},{"cell_type":"code","source":["import pyspark.sql.types as T\nfrom pyspark.sql.types import *\nimport json\n\n\n### configuration details to connect to Kafka source on Confluent cluster\nconf={'bootstrap.servers': 'pkc-4rn2p.canadacentral.azure.confluent.cloud:9092', \n      'security.protocol': 'SASL_SSL', \n      'sasl.mechanisms': 'PLAIN', \n      'sasl.username': 'D27IHIL45XD46XTF', \n      'sasl.password': 'UB3NYoxYI1NYvLMUEZrHuu5nYO9ZFR4jwAJMxQckb10QxvWtjU3zP1363Y2Akgcg',\n      'startingOffsets': starting_offsets,\n      'topic':kafka_topic\n     }\n\n\n### streaming specific configurations\ncheckpointPath = f'dbfs:/acerta/kafka-spark/checkpoint/v5/{kafka_topic}/'\ntriggerProcessingInterval = \"30 seconds\"\n\n\n### output locations\n# pivotRootDir = 'dbfs:/acerta/output/cube/pivot/'\n# cubeRunRootDir = f'dbfs:/acerta/output/cube/run/'\npivotRootDir = 'dbfs:/acerta/output/v5/cube/pivot/'\npivotSchemaDir = 'dbfs:/acerta/output/v5/cube/pivot/schema'\ncubeRunRootDir = f'dbfs:/acerta/output/v5/cube/run/'\noutputDfRunRootDir = f'dbfs:/acerta/output/v5/rca/run/'\noutputDfHistoryRootDir = f'dbfs:/acerta/output/v5/rca/history/'\n\n\n# ingress data configuration\ningress_schema_ddl = f\"`dataSourceId` STRING, `sourceFileId` STRING, `schemaVersion` STRING, `rows` ARRAY<MAP<STRING, STRING>>\"\ningress_schema = T._parse_datatype_string(ingress_schema_ddl)\n\n\n# pivot schema table configuration\npivot_schema_table_ddl = \"`dataSourceId` STRING, `pivotSchemaVersion` INTEGER, `pivotIndexDdl` STRING, `featureList` STRING, `updated_on` STRING\"\npivot_idx_ddl = \"`part_number` STRING, `serial_number` STRING, `timestamp` STRING, `station_list` ARRAY<STRING>, `measurement_date` DATE\" \n\n\n# map of configuration fields in the business-schema-mapping table to results dataframe column headers\nconfig_col_mapping = {\"line\":\"line\", \n                      \"station_config\":\"station\", \n                      \"sensor_config\":\"sensor\", \n                      \"part_number\":\"part_number\", \n                      \"serial_number\":\"serial_number\",\n                      \"measured_time\":\"timestamp\"\n                     }\n\n# data schema of mapped fields after business/logic schema mapping is applied\nmapped_schema = (StructType([StructField(\"line\", StringType(),True),\n                             StructField(\"part_number\", StringType(),True),\n                             StructField(\"serial_number\", StringType(),True),\n                             StructField(\"station\", StringType(),True),\n                             StructField(\"sensor\", StringType(),True),\n                             StructField(\"timestamp\", StringType(),True),\n                             StructField(\"measurements\", MapType(StringType(),StringType()), True)\n                            ])\n                )\n\n### For dev/testing only, creates local table mirrors of configuration tables\n# create and populate business schema mapping table\nbusinessSchemaTabDir = f'dbfs:/acerta/schema/business/'\nsourceDataMetaTabDir = f'dbfs:/acerta/schema/source_meta/'\n\nbusiness_schema_table_ddl = '`data_source_id` STRING, `schema_version` STRING, `schema_ddl` STRING, `logic_mapping` STRING'\nbusiness_schema_df = (spark\n                      .createDataFrame(\n                        data=[('b31d684c-d84b-44fa-9873-47c561542df9', '6', '`Line` STRING, `Station` STRING, `Part Number` STRING, `Database Code` STRING, `Serial Number` STRING, `Time` STRING, `Gun` STRING, `Job` STRING, `Pass` STRING, `Torque` STRING, `Ang (deg.)` STRING', '{\"line\":[\"Line\"], \"station_config\":[\"Line\", \"Station\"], \"sensor_config\":[\"Line\", \"Station\", \"Gun\", \"Job\"], \"part_number\": [\"Part_Number\"], \"serial_number\": [\"Serial_Number\"], \"measurement\":[\"Torque\", \"Ang__deg__\"], \"measured_time\":\"Time\"}'),\n                              ('d21ae4b8-51d8-4990-b9da-91c5cfc67927', '7', \"`serial_number` STRING, `process_name` STRING, `process_attribute_1` STRING, `process_attribute_2` STRING, `process_attribute_3` STRING, `process_attribute_4` STRING, `process_attribute_5` STRING, `data_element_name` STRING, `data_element_attribute_1` STRING, `data_element_attribute_2` STRING, `data_element_attribute_3` STRING, `data_element_attribute_4` STRING, `data_element_attribute_5` STRING, `location_name` STRING, `parent_location_name` STRING, `part_number` STRING, `data_value` STRING, `created` STRING, `trace` STRING, `test` STRING\", \n                               '{\"line\":[\"parent_location_name\"], \\\n                              \"station_config\":[\"location_name\"], \\\n                              \"sensor_config\":[\"parent_location_name\", \"location_name\", \"process_name\", \"process_attribute_1\", \"process_attribute_2\", \"process_attribute_3\", \"process_attribute_4\", \"process_attribute_5\", \"data_element_name\", \"data_element_attribute_1\", \"data_element_attribute_2\", \"data_element_attribute_3\", \"data_element_attribute_4\", \"data_element_attribute_5\"], \\\n                              \"part_number\": [\"part_number\"], \\\n                              \"serial_number\": [\"serial_number\"], \\\n                              \"measurement\":[\"data_value\"], \\\n                              \"measured_time\":\"created\"}'),\n                              ('86494c9c-143c-2e85-3b50-2021de22c403', '9', \"`serial_number` STRING, `process_name` STRING, `process_attribute_1` STRING, `process_attribute_2` STRING, `process_attribute_3` STRING, `process_attribute_4` STRING, `process_attribute_5` STRING, `data_element_name` STRING, `data_element_attribute_1` STRING, `data_element_attribute_2` STRING, `data_element_attribute_3` STRING, `data_element_attribute_4` STRING, `data_element_attribute_5` STRING, `location_name` STRING, `parent_location_name` STRING, `part_number` STRING, `data_value` STRING, `created` STRING, `trace` STRING, `test` STRING\", \n                               '{\"line\":[\"parent_location_name\"], \\\n                              \"station_config\":[\"location_name\"], \\\n                              \"sensor_config\":[\"parent_location_name\", \"location_name\", \"process_name\", \"process_attribute_1\", \"process_attribute_2\", \"process_attribute_3\", \"process_attribute_4\", \"process_attribute_5\", \"data_element_name\", \"data_element_attribute_1\", \"data_element_attribute_2\", \"data_element_attribute_3\", \"data_element_attribute_4\", \"data_element_attribute_5\"], \\\n                              \"part_number\": [\"part_number\"], \\\n                              \"serial_number\": [\"serial_number\"], \\\n                              \"measurement\":[\"data_value\"], \\\n                              \"measured_time\":\"created\"}'),\n                              ('2665e070-cbde-ac9f-d6d0-228d82bc75ac', '8', \"`serial_number` STRING, `process_name` STRING, `process_attribute_1` STRING, `process_attribute_2` STRING, `process_attribute_3` STRING, `process_attribute_4` STRING, `process_attribute_5` STRING, `data_element_name` STRING, `data_element_attribute_1` STRING, `data_element_attribute_2` STRING, `data_element_attribute_3` STRING, `data_element_attribute_4` STRING, `data_element_attribute_5` STRING, `location_name` STRING, `parent_location_name` STRING, `part_number` STRING, `data_value` STRING, `created` STRING, `trace` STRING, `test` STRING\", \n                               '{\"line\":[\"parent_location_name\"], \\\n                              \"station_config\":[\"location_name\"], \\\n                              \"sensor_config\":[\"parent_location_name\", \"location_name\", \"process_name\", \"process_attribute_1\", \"process_attribute_2\", \"process_attribute_3\", \"process_attribute_4\", \"process_attribute_5\", \"data_element_name\", \"data_element_attribute_1\", \"data_element_attribute_2\", \"data_element_attribute_3\", \"data_element_attribute_4\", \"data_element_attribute_5\"], \\\n                              \"part_number\": [\"part_number\"], \\\n                              \"serial_number\": [\"serial_number\"], \\\n                              \"measurement\":[\"data_value\"], \\\n                              \"measured_time\":\"created\"}')\n                             ],\n                        schema=T._parse_datatype_string(business_schema_table_ddl)\n                      )\n                     )\nbusiness_schema_df.registerTempTable(\"business_schema_table\")\ndbutils.fs.rm(businessSchemaTabDir, True)\nbusiness_schema_df.write.parquet(businessSchemaTabDir)  \ndisplay(spark.sql(\"select * from business_schema_table\"))\n\n# create data source meta data table\ndata_source_meta_table_ddl = '`data_source_id` STRING, `client` STRING, `location` STRING, `line` STRING, `source_type` STRING, `folder_location` STRING'\ndata_source_meta_df = (spark\n                      .createDataFrame(\n                        data=[('b31d684c-d84b-44fa-9873-47c561542df9', 'Borg Warner', 'XYZ', 'L14', 'csv', 'server://path'),\n                              ('d21ae4b8-51d8-4990-b9da-91c5cfc67927', 'Dana', 'Birmingham', 'ASC1', 'csv', 'server://path'),\n                              ('86494c9c-143c-2e85-3b50-2021de22c403', 'Dana', 'Dry Ridge', '700_line', 'csv', 'server://path'),\n                              ('2665e070-cbde-ac9f-d6d0-228d82bc75ac', 'Dana', 'Columbia', 'Loop_1', 'csv', 'server://path')\n                             ],\n                        schema=T._parse_datatype_string(data_source_meta_table_ddl)\n                      )\n                     )\ndata_source_meta_df.registerTempTable(\"data_source_meta_table\")\ndbutils.fs.rm(sourceDataMetaTabDir, True)\ndata_source_meta_df.write.parquet(sourceDataMetaTabDir)  \ndisplay(spark.sql(\"select * from data_source_meta_table\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"978a037c-a2b7-461b-a172-bf7acb5c223c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3158978682445717&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>       <span class=\"ansi-blue-fg\">&#39;sasl.username&#39;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;D27IHIL45XD46XTF&#39;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     11</span>       <span class=\"ansi-blue-fg\">&#39;sasl.password&#39;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;UB3NYoxYI1NYvLMUEZrHuu5nYO9ZFR4jwAJMxQckb10QxvWtjU3zP1363Y2Akgcg&#39;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 12</span><span class=\"ansi-red-fg\">       </span><span class=\"ansi-blue-fg\">&#39;startingOffsets&#39;</span><span class=\"ansi-blue-fg\">:</span> starting_offsets<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>       <span class=\"ansi-blue-fg\">&#39;topic&#39;</span><span class=\"ansi-blue-fg\">:</span>kafka_topic\n<span class=\"ansi-green-intense-fg ansi-bold\">     14</span>      }\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;starting_offsets&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;starting_offsets&#39; is not defined","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3158978682445717&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span>       <span class=\"ansi-blue-fg\">&#39;sasl.username&#39;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;D27IHIL45XD46XTF&#39;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     11</span>       <span class=\"ansi-blue-fg\">&#39;sasl.password&#39;</span><span class=\"ansi-blue-fg\">:</span> <span class=\"ansi-blue-fg\">&#39;UB3NYoxYI1NYvLMUEZrHuu5nYO9ZFR4jwAJMxQckb10QxvWtjU3zP1363Y2Akgcg&#39;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-fg\">---&gt; 12</span><span class=\"ansi-red-fg\">       </span><span class=\"ansi-blue-fg\">&#39;startingOffsets&#39;</span><span class=\"ansi-blue-fg\">:</span> starting_offsets<span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>       <span class=\"ansi-blue-fg\">&#39;topic&#39;</span><span class=\"ansi-blue-fg\">:</span>kafka_topic\n<span class=\"ansi-green-intense-fg ansi-bold\">     14</span>      }\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;starting_offsets&#39; is not defined</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e70f5b5c-237d-4214-ae58-10f0bbc8881b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"common","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3158978682445715}},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"markdown","source":["##Housekeeping script for all lines\nThis script contains common configurations needed to transform all lines. \n\n###Configuration variables/set up included in this script:\n1. Authentication detail to connect to Kafka topic on Confluent cluster\n2. The check point location, output root directory, and trigger interval for the data stream\n3. The output directory of DF_RUN (for RCA)\n4. The technical schema of Kafka messages\n5. Schema of the pivot-schema table\n6. Column name mapping and schema of mapped fields for running the business schema mapping logic\n7. Create local business-schema-mapping table and source-meta-data table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"246ba9d3-ae01-4c8a-86ab-3d39722dd344"}}},{"cell_type":"code","source":["import pyspark.sql.types as T\nfrom pyspark.sql.types import *\nimport json\n\n\n### configuration details to connect to Kafka source on Confluent cluster\nconf={'bootstrap.servers': 'pkc-4rn2p.canadacentral.azure.confluent.cloud:9092', \n      'security.protocol': 'SASL_SSL', \n      'sasl.mechanisms': 'PLAIN', \n      'sasl.username': 'D27IHIL45XD46XTF', \n      'sasl.password': 'UB3NYoxYI1NYvLMUEZrHuu5nYO9ZFR4jwAJMxQckb10QxvWtjU3zP1363Y2Akgcg',\n      'startingOffsets':'earliest',\n      #'startingOffsets':'{\"data_test_topic\":{\"0\":252}}',\n      'topic':kafka_topic\n     }\n\n\n### streaming specific configurations\ncheckpointPath = f'dbfs:/acerta/kafka-spark/checkpoint/{kafka_topic}/'\ntriggerProcessingInterval = \"30 seconds\"\n\n\n### output locations\n# pivotRootDir = 'dbfs:/acerta/output/cube/pivot/'\n# cubeRunRootDir = f'dbfs:/acerta/output/cube/run/'\npivotRootDir = 'dbfs:/acerta/output/test/cube/pivot/'\ncubeRunRootDir = f'dbfs:/acerta/output/test/cube/run/'\noutputDfRunRootDir = f'dbfs:/acerta/output/rca/run/'\noutputDfHistoryRootDir = f'dbfs:/acerta/output/rca/history/'\n\n\n# ingress data configuration\ningress_schema_ddl = f\"`dataSourceId` STRING, `sourceFileId` STRING, `schemaVersion` STRING, `rows` ARRAY<MAP<STRING, STRING>>\"\ningress_schema = T._parse_datatype_string(ingress_schema_ddl)\n\n\n# pivot schema table configuration\npivot_schema_table_ddl = \"`dataSourceId` STRING, `schemaVersion` STRING, `pivotSchemaVersion` INT, `pivotIndexDdl` STRING, `featureList` STRING, `updated_on` STRING\"\npivot_idx_ddl = \"`part_number` STRING, `serial_number` STRING, `timestamp` STRING, `station_list` ARRAY<STRING>, `measurement_date` DATE\" \n\n\n# map of configuration fields in the business-schema-mapping table to results dataframe column headers\nconfig_col_mapping = {\"line\":\"line\", \n                      \"station_config\":\"station\", \n                      \"sensor_config\":\"sensor\", \n                      \"part_number\":\"part_number\", \n                      \"serial_number\":\"serial_number\",\n                      \"measured_time\":\"timestamp\"\n                     }\n\n# data schema of mapped fields after business/logic schema mapping is applied\nmapped_schema = (StructType([StructField(\"line\", StringType(),True),\n                             StructField(\"part_number\", StringType(),True),\n                             StructField(\"serial_number\", StringType(),True),\n                             StructField(\"station\", StringType(),True),\n                             StructField(\"sensor\", StringType(),True),\n                             StructField(\"timestamp\", StringType(),True),\n                             StructField(\"measurements\", MapType(StringType(),StringType()), True)\n                            ])\n                )\n\n### For dev/testing only, creates local table mirrors of configuration tables\n# create and populate business schema mapping table\nbusinessSchemaTabDir = f'dbfs:/acerta/schema/business/'\nsourceDataMetaTabDir = f'dbfs:/acerta/schema/source_meta/'\n\nbusiness_schema_table_ddl = '`data_source_id` STRING, `schema_version` STRING, `schema_ddl` STRING, `logic_mapping` STRING'\nbusiness_schema_df = (spark\n                      .createDataFrame(\n                        data=[('0.1.0', '0.1.1', '`Line` STRING, `Station` STRING, `Part Number` STRING, `Database Code` STRING, `Serial Number` STRING, `Time` STRING, `Gun` STRING, `Job` STRING, `Pass` STRING, `Torque` STRING, `Ang (deg.)` STRING', '{\"line\":[\"Line\"], \"station_config\":[\"Line\", \"Station\"], \"sensor_config\":[\"Line\", \"Station\", \"Gun\", \"Job\"], \"part_number\": [\"Part_Number\"], \"serial_number\": [\"Serial_Number\"], \"measurement\":[\"Torque\", \"Ang__deg__\"], \"measured_time\":\"Time\"}')],\n                        schema=T._parse_datatype_string(business_schema_table_ddl)\n                      )\n                     )\nbusiness_schema_df.registerTempTable(\"business_schema_table\")\ndbutils.fs.rm(businessSchemaTabDir, True)\nbusiness_schema_df.write.parquet(businessSchemaTabDir)  \ndisplay(spark.sql(\"select * from business_schema_table\"))\n\n# create data source meta data table\ndata_source_meta_table_ddl = '`data_source_id` STRING, `client` STRING, `location` STRING, `line` STRING, `source_type` STRING, `folder_location` STRING'\ndata_source_meta_df = (spark\n                      .createDataFrame(\n                        data=[('0.1.0', 'Borg Warner', 'XYZ', 'L14', 'csv', 'server://path')],\n                        schema=T._parse_datatype_string(data_source_meta_table_ddl)\n                      )\n                     )\ndata_source_meta_df.registerTempTable(\"data_source_meta_table\")\ndbutils.fs.rm(sourceDataMetaTabDir, True)\ndata_source_meta_df.write.parquet(sourceDataMetaTabDir)  \ndisplay(spark.sql(\"select * from data_source_meta_table\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"978a037c-a2b7-461b-a172-bf7acb5c223c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3972027611227718&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span>       <span class=\"ansi-blue-fg\">&#39;startingOffsets&#39;</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">&#39;earliest&#39;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>       <span class=\"ansi-red-fg\">#&#39;startingOffsets&#39;:&#39;{&#34;data_test_topic&#34;:{&#34;0&#34;:252}}&#39;,</span>\n<span class=\"ansi-green-fg\">---&gt; 14</span><span class=\"ansi-red-fg\">       </span><span class=\"ansi-blue-fg\">&#39;topic&#39;</span><span class=\"ansi-blue-fg\">:</span>kafka_topic\n<span class=\"ansi-green-intense-fg ansi-bold\">     15</span>      }\n<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> \n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;kafka_topic&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;kafka_topic&#39; is not defined","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3972027611227718&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span>       <span class=\"ansi-blue-fg\">&#39;startingOffsets&#39;</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">&#39;earliest&#39;</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>       <span class=\"ansi-red-fg\">#&#39;startingOffsets&#39;:&#39;{&#34;data_test_topic&#34;:{&#34;0&#34;:252}}&#39;,</span>\n<span class=\"ansi-green-fg\">---&gt; 14</span><span class=\"ansi-red-fg\">       </span><span class=\"ansi-blue-fg\">&#39;topic&#39;</span><span class=\"ansi-blue-fg\">:</span>kafka_topic\n<span class=\"ansi-green-intense-fg ansi-bold\">     15</span>      }\n<span class=\"ansi-green-intense-fg ansi-bold\">     16</span> \n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;kafka_topic&#39; is not defined</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e70f5b5c-237d-4214-ae58-10f0bbc8881b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"common","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3972027611227716}},"nbformat":4,"nbformat_minor":0}

# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

  # Specify the trigger event to start the build pipeline.
# In this case, new code merged into the develop branch initiates a new build.

variables:
  workingDirectory: '$(System.DefaultWorkingDirectory)/Artifacts'
  pythonVersion: 3.7

trigger:
- develop

pool:
  vmImage: ubuntu-latest  

# Install Python. The version must match the version on the Databricks cluster.
steps:
- task: UsePythonVersion@0
  displayName: 'Use Python 3.7'
  inputs:
    versionSpec: 3.7

# Install required Python modules, including databricks-connect, required to execute a unit test
# on a cluster.
- script: |
    pip install pytest requests setuptools wheel
    pip install flake8  pytest-cov
  displayName: 'Load Python Dependencies'

# get the code

- checkout: self
  persistCredentials: true
  clean: true

- script: git checkout develop
  displayName: 'Get Latest Develop Branch'

- task: CopyFiles@2
  displayName: 'Copy Files to:  $(Build.Repository.LocalPath)'
  inputs:
    SourceFolder: '$(Build.Repository.LocalPath)'
    TargetFolder: ' $(build.artifactstagingdirectory)'
- task: PublishBuildArtifacts@1
  displayName: 'Publish Artifact: DatabricksArtifacts'
  inputs:
    ArtifactName: LP-Cube-Artifacts

  